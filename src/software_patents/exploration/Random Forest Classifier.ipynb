{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skll.metrics import kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\n",
    "    r\"C:\\Users\\Tobias\\OneDrive\\Bachelor Thesis\\Empirical Look at Software Patents\\test\"\n",
    ")\n",
    "\n",
    "dftrain = pd.read_pickle(\"train_sample.pickle\")\n",
    "# dftrain = dftrain[['label', 'text']]\n",
    "dftest = pd.read_pickle(\"test_sample.pickle\")\n",
    "# dftest = dftest[['label', 'text']]\n",
    "df = pd.read_pickle(\"classified_sample_wtext.pickle\")\n",
    "# df = df[['label', 'text']]\n",
    "dfover = pd.read_pickle(\"real_oversampling_400+luksoft.pickle\")\n",
    "\n",
    "kappa_scorer = make_scorer(kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using only 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV with StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63063063  0.8047619   0.46052632  0.63063063  0.68421053  0.44680851\n",
      "  1.          0.87459807  0.72340426  0.62379421]\n",
      "0.687936505704\n"
     ]
    }
   ],
   "source": [
    "### Pipelining\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1, 4), max_df=0.7, analyzer=\"word\")),\n",
    "        #                    ('to_dense', DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        #                    ('scale', StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "        (\"sel\", SelectKBest(chi2, k=200)),\n",
    "        #                    ('pca', PCA(n_components=300)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                #                                                   max_depth=10,\n",
    "                max_features=0.3,\n",
    "                #                                                   min_samples_leaf=5,\n",
    "                #                                                   oob_score=True, warm_start=True,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "### Cross-Validation\n",
    "##### Define CV\n",
    "cv = StratifiedKFold(\n",
    "    dftest.label, n_folds=10, indices=None, shuffle=True, random_state=6\n",
    ")\n",
    "scores_f = cross_val_score(\n",
    "    text_clf,\n",
    "    dftest.text.values,\n",
    "    dftest.software_man_class.values,\n",
    "    cv=cv,\n",
    "    scoring=kappa_scorer,\n",
    "    n_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__oob_score: False\n"
     ]
    }
   ],
   "source": [
    "class DenseTransformer:\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    #    'vect__max_df': (0.7, 0.8),\n",
    "    #    'vect__min_df': (0),\n",
    "    #    'vect__stop_words': ('english', None),\n",
    "    #    'vect__analyzer': ('word', None),\n",
    "    #    'vect__strip_accents': ('unicode', None)\n",
    "    #    'vect__ngram_range': ((1,4), (1,5)),\n",
    "    #    'scale__with_std': (True, False),\n",
    "    #    'sel__score_func': (chi2, f_classif),\n",
    "    #    'sel__k': (150, 200, 250),\n",
    "    #    'pca__n_components': (100, 200, 500),\n",
    "    #    'pca_whiten': (True, False),\n",
    "    #    'clf__n_estimators': (2000, 5000, 10000),\n",
    "    #    'clf__criterion': ('gini', 'entropy'),\n",
    "    #    'clf__max_depth': (10, 11, 12, 15, 20, 25),\n",
    "    #    'clf__min_samples_leaf': (1, 3, 5, 7),\n",
    "    #    'clf__max_features': (2, 2.75, 0.3, 3.25, 3.5, 4),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"vect\",\n",
    "            CountVectorizer(\n",
    "                #                min_df=0\n",
    "                max_df=0.7,\n",
    "                analyzer=\"word\",\n",
    "                ngram_range=(1, 4),\n",
    "            ),\n",
    "        ),\n",
    "        #                     ('scale', StandardScaler(\n",
    "        #                copy=True,\n",
    "        #                with_mean=False,\n",
    "        #                with_std=True\n",
    "        #            )),\n",
    "        (\n",
    "            \"sel\",\n",
    "            SelectKBest(\n",
    "                score_func=chi2,\n",
    "                k=200,\n",
    "            ),\n",
    "        ),\n",
    "        #                     ('to_dense', DenseTransformer()),\n",
    "        #                     ('pca', PCA(\n",
    "        #                n_components=500\n",
    "        #            )),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                min_samples_leaf=5,\n",
    "                max_features=0.3,\n",
    "                max_depth=10,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cvg = StratifiedKFold(\n",
    "    dftest.label, n_folds=5, indices=None, shuffle=True, random_state=None\n",
    ")\n",
    "gs_clf = GridSearchCV(\n",
    "    text_clf, parameters, n_jobs=3, scoring=kappa_scorer, error_score=0, cv=cvg\n",
    ")  #### !!!ATTENTION: JOBS!!!\n",
    "gs_clf = gs_clf.fit(dftest.text.values, dftest.software_man_class.values)\n",
    "\n",
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "for _param_name in sorted(parameters.keys()):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.97      1.00      0.99        35\n",
      "   software       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97        40\n",
      "\n",
      "[[35  0]\n",
      " [ 1  4]]\n",
      "0.875\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.97      1.00      0.99        35\n",
      "   software       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97        40\n",
      "\n",
      "[[35  0]\n",
      " [ 1  4]]\n",
      "0.875\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.97      1.00      0.99        35\n",
      "   software       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97        40\n",
      "\n",
      "[[35  0]\n",
      " [ 1  4]]\n",
      "0.875\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.97      0.97      0.97        35\n",
      "   software       0.80      0.80      0.80         5\n",
      "\n",
      "avg / total       0.95      0.95      0.95        40\n",
      "\n",
      "[[34  1]\n",
      " [ 1  4]]\n",
      "0.771428571429\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       1.00      0.97      0.99        35\n",
      "   software       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.98      0.97      0.98        40\n",
      "\n",
      "[[34  1]\n",
      " [ 0  5]]\n",
      "0.894736842105\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.97      1.00      0.99        35\n",
      "   software       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97        40\n",
      "\n",
      "[[35  0]\n",
      " [ 1  4]]\n",
      "0.875\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.94      0.94      0.94        35\n",
      "   software       0.60      0.60      0.60         5\n",
      "\n",
      "avg / total       0.90      0.90      0.90        40\n",
      "\n",
      "[[33  2]\n",
      " [ 2  3]]\n",
      "0.542857142857\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.97      1.00      0.99        35\n",
      "   software       1.00      0.80      0.89         5\n",
      "\n",
      "avg / total       0.98      0.97      0.97        40\n",
      "\n",
      "[[35  0]\n",
      " [ 1  4]]\n",
      "0.875\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.92      0.97      0.94        35\n",
      "   software       0.67      0.40      0.50         5\n",
      "\n",
      "avg / total       0.89      0.90      0.89        40\n",
      "\n",
      "[[34  1]\n",
      " [ 3  2]]\n",
      "0.448275862069\n",
      "------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "nonsoftware       0.91      0.91      0.91        35\n",
      "   software       0.40      0.40      0.40         5\n",
      "\n",
      "avg / total       0.85      0.85      0.85        40\n",
      "\n",
      "[[32  3]\n",
      " [ 3  2]]\n",
      "0.314285714286\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class DenseTransformer:\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "def func(a) -> int:\n",
    "    if a == \"nonsoftware\":\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(max_df=0.7, ngram_range=(1, 4), analyzer=\"word\")),\n",
    "        #                    ('to_dense', DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        (\"sel\", SelectKBest(chi2, k=200)),\n",
    "        #                    ('pca', PCA(n_components=300)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                max_features=0.3,\n",
    "                n_jobs=-1,\n",
    "                #                            max_depth=10, min_samples_leaf=5,)\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(\n",
    "    dftest.label.values, n_iter=10, test_size=0.1, random_state=10\n",
    ")\n",
    "for train_index, test_index in sss:\n",
    "    x_train, x_test = dftest.text.iloc[train_index], dftest.text.iloc[test_index]\n",
    "    y_train, y_test = dftest.label.iloc[train_index], dftest.label.iloc[test_index]\n",
    "    classifier = text_clf.fit(x_train, y_train)\n",
    "    predicted = text_clf.predict(x_test)\n",
    "\n",
    "    vfunc = np.vectorize(func)\n",
    "    predicted_bool = vfunc(predicted)\n",
    "    y_test_bool = vfunc(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 400 and Lukas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV with StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.37292162  0.43083004  0.34246575  0.25890736  0.31428571  0.43083004\n",
      "  0.75460123  0.40344168  0.37292162  0.52473596]\n",
      "0.42059410146\n"
     ]
    }
   ],
   "source": [
    "### Pipelining\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1, 4), max_df=0.7, analyzer=\"word\")),\n",
    "        #                    ('to_dense', DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        (\"sel\", SelectKBest(chi2, k=200)),\n",
    "        #                    ('pca', PCA(n_components=300)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                max_depth=10,\n",
    "                max_features=0.3,\n",
    "                min_samples_leaf=5,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "### Cross-Validation\n",
    "##### Define CV\n",
    "cv = StratifiedKFold(\n",
    "    df.label, n_folds=10, indices=None, shuffle=True, random_state=None\n",
    ")\n",
    "scores_f = cross_val_score(\n",
    "    text_clf,\n",
    "    df.text.values,\n",
    "    df.software_man_class.values,\n",
    "    cv=cv,\n",
    "    scoring=kappa_scorer,\n",
    "    n_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does not work. I would contribute all the additional bias to the difference in definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseTransformer:\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "def func(a) -> int:\n",
    "    if a == \"nonsoftware\":\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(max_df=0.7, ngram_range=(1, 4), analyzer=\"words\")),\n",
    "        #                    ('to_dense', DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        (\"sel\", SelectKBest(chi2, k=200)),\n",
    "        #                    ('pca', PCA(n_components=300)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=1000,\n",
    "                criterion=\"gini\",\n",
    "                max_depth=10,\n",
    "                max_features=0.3,\n",
    "                min_samples_leaf=5,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(\n",
    "    df.label.values, n_iter=10, test_size=0.2, random_state=None\n",
    ")\n",
    "for train_index, test_index in sss:\n",
    "    x_train, x_test = df.text.iloc[train_index], df.text.iloc[test_index]\n",
    "    y_train, y_test = df.label.iloc[train_index], df.label.iloc[test_index]\n",
    "    classifier = text_clf.fit(x_train, y_train)\n",
    "    predicted = text_clf.predict(x_test)\n",
    "\n",
    "    vfunc = np.vectorize(func)\n",
    "    predicted_bool = vfunc(predicted)\n",
    "    y_test_bool = vfunc(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Lukas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV with StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0326087   0.45714286 -0.0326087   0.          0.13103448  0.32413793\n",
      " -0.08617594  0.46002805 -0.03340292  0.15057915]\n",
      "0.13381262154\n"
     ]
    }
   ],
   "source": [
    "### Pipelining\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1, 4), max_df=0.7, analyzer=\"word\")),\n",
    "        #                    ('to_dense', DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        (\"sel\", SelectKBest(chi2, k=200)),\n",
    "        #                    ('pca', PCA(n_components=300)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                max_depth=10,\n",
    "                max_features=0.3,\n",
    "                min_samples_leaf=5,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "### Cross-Validation\n",
    "##### Define CV\n",
    "cv = StratifiedKFold(\n",
    "    dftrain.label, n_folds=10, indices=None, shuffle=True, random_state=None\n",
    ")\n",
    "scores_f = cross_val_score(\n",
    "    text_clf,\n",
    "    dftrain.text.values,\n",
    "    dftrain.software_man_class.values,\n",
    "    cv=cv,\n",
    "    scoring=kappa_scorer,\n",
    "    n_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devastating! Of course, the classifier is not set up for this work, but identifying latent topics such as automatisation is very difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL OVERSAMPLING - 400 and Lukas Software Patents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV with StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6259542   0.47058824  0.671875    0.608       0.47058824  0.77981651\n",
      "  0.51569507  0.4679803   0.53648069  0.78947368]\n",
      "0.593645191656\n"
     ]
    }
   ],
   "source": [
    "### Pipelining\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1, 4), max_df=0.7, analyzer=\"word\")),\n",
    "        #                    ('to_dense', DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        (\"sel\", SelectKBest(chi2, k=200)),\n",
    "        #                    ('pca', PCA(n_components=300)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                max_depth=10,\n",
    "                max_features=0.3,\n",
    "                min_samples_leaf=5,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "### Cross-Validation\n",
    "##### Define CV\n",
    "cv = StratifiedKFold(\n",
    "    dfover.label, n_folds=10, indices=None, shuffle=True, random_state=None\n",
    ")\n",
    "scores_f = cross_val_score(\n",
    "    text_clf,\n",
    "    dfover.text.values,\n",
    "    dfover.software_man_class.values,\n",
    "    cv=cv,\n",
    "    scoring=kappa_scorer,\n",
    "    n_jobs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice try! This kind of oversampling is not working. Of course, I used the same classifier as above and maybe some grid search will help. The problem might be, that these software patents are very specific and since overfitting is already one of my problem it is now working in a different way towards Lukas' software patents. Regarding the number of software patents (bh2007: 54, Lukas: ~85), this might be one explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dftrain_1 = dftrain[dftrain.label == \"software\"]\n",
    "dftrain_1 = dftrain_1[\n",
    "    [\n",
    "        \"highly_uncertain\",\n",
    "        \"patentnr\",\n",
    "        \"software_man_class\",\n",
    "        \"classnr\",\n",
    "        \"week\",\n",
    "        \"year\",\n",
    "        \"label\",\n",
    "        \"text\",\n",
    "    ]\n",
    "]\n",
    "dftrain_1 = dftrain_1.reset_index(drop=True)\n",
    "df_over = pd.concat([dftest, dftrain_1], axis=0, ignore_index=True).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "df_over = df_over[\n",
    "    [\n",
    "        \"highly_uncertain\",\n",
    "        \"patentnr\",\n",
    "        \"software_man_class\",\n",
    "        \"classnr\",\n",
    "        \"week\",\n",
    "        \"year\",\n",
    "        \"label\",\n",
    "        \"text\",\n",
    "    ]\n",
    "]\n",
    "df_over.to_pickle(\"real_oversampling_400+luksoft.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including patent classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    #     For data grouped by feature, select subset of data at a provided key.\n",
    "\n",
    "    #     The data is expected to be stored in a 2D data structure, where the first\n",
    "    #     index is over features and the second is over samples.  i.e.\n",
    "\n",
    "    #     >> len(data[key]) == n_samples\n",
    "\n",
    "    #     Please note that this is the opposite convention to sklearn feature\n",
    "    #     matrixes (where the first index corresponds to sample).\n",
    "\n",
    "    #     ItemSelector only requires that the collection implement getitem\n",
    "    #     (data[key]).  Examples include: a dict of lists, 2D numpy array, Pandas\n",
    "    #     DataFrame, numpy record array, etc.\n",
    "\n",
    "    #     >> data = {'a': [1, 5, 2, 5, 2, 8],\n",
    "    #                'b': [9, 4, 1, 4, 1, 3]}\n",
    "    #     >> ds = ItemSelector(key='a')\n",
    "    #     >> data['a'] == ds.transform(data)\n",
    "\n",
    "    #     ItemSelector is not designed to handle data grouped by sample.  (e.g. a\n",
    "    #     list of dicts).  If your data is structured this way, consider a\n",
    "    #     transformer along the lines of `sklearn.feature_extraction.DictVectorizer`.\n",
    "\n",
    "    #     Parameters\n",
    "    #     ----------\n",
    "    #     key : hashable, required\n",
    "    #         The key corresponding to the desired value in a mappable.\n",
    "\n",
    "    def __init__(self, key) -> None:\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "\n",
    "\n",
    "patent_clf = Pipeline(\n",
    "    [\n",
    "        # Use FeatureUnion to combine text with classnr\n",
    "        (\n",
    "            \"union\",\n",
    "            FeatureUnion(\n",
    "                transformer_list=[\n",
    "                    (\n",
    "                        \"classnr\",\n",
    "                        Pipeline(\n",
    "                            [\n",
    "                                (\"selector\", ItemSelector(key=\"classnr\")),\n",
    "                            ]\n",
    "                        ),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"text\",\n",
    "                        Pipeline(\n",
    "                            [\n",
    "                                (\"selector\", ItemSelector(key=\"text\")),\n",
    "                                (\n",
    "                                    \"vect\",\n",
    "                                    CountVectorizer(\n",
    "                                        ngram_range=(1, 4), max_df=0.7, analyzer=\"word\"\n",
    "                                    ),\n",
    "                                ),\n",
    "                                (\"sel\", SelectKBest(chi2, k=200)),\n",
    "                            ]\n",
    "                        ),\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                max_depth=10,\n",
    "                max_features=0.3,\n",
    "                min_samples_leaf=5,\n",
    "                #                           oob_score=True, warm_start=True,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "patent_clf = patent_clf.fit(\n",
    "    dftest[[\"classnr\", \"text\"]], dftest.software_man_class.values\n",
    ")\n",
    "y = patent_clf.predict(dftest[[\"classnr\", \"text\"]])\n",
    "\n",
    "### Cross-Validation\n",
    "##### Define CV\n",
    "# cv = StratifiedKFold(dftest.label, n_folds=10, indices=None, shuffle=True, random_state=None)\n",
    "# scores_f = cross_val_score(patent_clf, dftest[['text', 'classnr']], dftest.software_man_class.values, cv=cv, scoring=kappa_scorer, n_jobs=1)\n",
    "# print(scores_f)\n",
    "# print(scores_f.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = CountVectorizer(ngram_range=(1, 1), max_df=0.7, analyzer=\"word\").fit_transform(\n",
    "    dftest.text.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 39623)\n"
     ]
    }
   ],
   "source": [
    "data = data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10582409,  0.10481709,  0.04807325,  0.0396829 ,  0.03566621,\n",
       "        0.0258221 ,  0.01914194,  0.01700291,  0.01588821,  0.01379683,\n",
       "        0.01341883,  0.012811  ,  0.01217448,  0.01171879,  0.01158666,\n",
       "        0.01095529,  0.01070691,  0.00968206,  0.00931362,  0.00904757,\n",
       "        0.00845281,  0.00822351,  0.00803343,  0.00783608,  0.00752051,\n",
       "        0.00708226,  0.00690281,  0.00685378,  0.00669231,  0.00662687,\n",
       "        0.00637655,  0.00634484,  0.00620333,  0.00601109,  0.00586248,\n",
       "        0.00584506,  0.00568548,  0.00547855,  0.00536456,  0.00515166,\n",
       "        0.00493291,  0.0048548 ,  0.00483365,  0.0048139 ,  0.00471311,\n",
       "        0.00458722,  0.0045315 ,  0.00438892,  0.00426935,  0.00416489,\n",
       "        0.00402159,  0.00398604,  0.0039372 ,  0.00386506,  0.00372854,\n",
       "        0.00368302,  0.00359796,  0.00354931,  0.00347091,  0.00343143,\n",
       "        0.00338491,  0.00330203,  0.00327289,  0.00311969,  0.00305027,\n",
       "        0.00298252,  0.00292361,  0.00288909,  0.00285151,  0.00282406,\n",
       "        0.00271604,  0.00268274,  0.0026241 ,  0.00258686,  0.00254667,\n",
       "        0.00251   ,  0.00245602,  0.0024074 ,  0.00235391,  0.00234947,\n",
       "        0.00230074,  0.00225373,  0.00221448,  0.0021609 ,  0.00214987,\n",
       "        0.00209544,  0.00204629,  0.00203407,  0.00200931,  0.00199424,\n",
       "        0.00197782,  0.0019603 ,  0.00192834,  0.0018546 ,  0.00184626,\n",
       "        0.00183005,  0.00181246,  0.00176836,  0.00175184,  0.0017399 ,\n",
       "        0.00172048,  0.00171006,  0.00166582,  0.00165655,  0.00165178,\n",
       "        0.0016084 ,  0.0015939 ,  0.00158546,  0.00157104,  0.00155424,\n",
       "        0.00152278,  0.00146824,  0.001461  ,  0.00145103,  0.00142517,\n",
       "        0.00140707,  0.0014057 ,  0.00138378,  0.00136327,  0.00134431,\n",
       "        0.00133328,  0.00132243,  0.00130368,  0.00129505,  0.00125665,\n",
       "        0.00123795,  0.00121397,  0.00120221,  0.00119924,  0.00117843,\n",
       "        0.00116263,  0.00115114,  0.00113961,  0.00113302,  0.00110665,\n",
       "        0.00109742,  0.00108202,  0.00107685,  0.00106631,  0.00105381,\n",
       "        0.0010357 ,  0.0010312 ,  0.00102251,  0.00100626,  0.00099463,\n",
       "        0.00098532,  0.00096551,  0.00096298,  0.0009561 ,  0.00095218,\n",
       "        0.00093539,  0.00093075,  0.00091623,  0.00091563,  0.00091113,\n",
       "        0.00088789,  0.00088466,  0.0008786 ,  0.00087431,  0.00086108,\n",
       "        0.00085507,  0.00083956,  0.00083524,  0.00082226,  0.00081643,\n",
       "        0.00080769,  0.00079912,  0.00079253,  0.00077453,  0.00076895,\n",
       "        0.00076674,  0.00074972,  0.00074156,  0.00073114,  0.00072743,\n",
       "        0.00072448,  0.00071379,  0.00070743,  0.00069536,  0.00068541,\n",
       "        0.00068249,  0.00067838,  0.00066748,  0.00066451,  0.00066241,\n",
       "        0.0006531 ,  0.00064971,  0.00063557,  0.00063263,  0.0006287 ,\n",
       "        0.00061922,  0.0006077 ,  0.00060449,  0.00059662,  0.00058773,\n",
       "        0.00058481,  0.00058232,  0.00057276,  0.00056938,  0.00056536])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-952fa45d1751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m####### Does have problems with multiprocessing. You never know...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mscores_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdftest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdftest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftware_man_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkappa_scorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1361\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, args, kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1459\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mtrees\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                 \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m                 \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0msub\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[0;32m     78\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                     \u001b[1;31m# if the parameter is deprecated, don't show it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\warnings.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *exc_info)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filters_mutated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowwarning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showwarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class DenseTransformer:\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "### Pipelining\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(ngram_range=(1, 1), max_df=0.7, analyzer=\"word\")),\n",
    "        (\"to_dense\", DenseTransformer()),\n",
    "        #                    ('tfidf', TfidfVectorizer(max_df=0.8)),\n",
    "        (\"scale\", StandardScaler(copy=True, with_mean=False, with_std=True)),\n",
    "        #                    ('sel', SelectKBest(chi2, k=200)),\n",
    "        (\"pca\", PCA(n_components=175)),\n",
    "        #                    ('tfidf_trans', TfidfTransformer(sublinear_tf=True)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=5000,\n",
    "                criterion=\"gini\",\n",
    "                max_depth=10,\n",
    "                max_features=0.3,\n",
    "                min_samples_leaf=5,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "### Cross-Validation\n",
    "##### Define CV\n",
    "####### Does have problems with multiprocessing. You never know...\n",
    "cv = StratifiedKFold(\n",
    "    dftest.label, n_folds=10, indices=None, shuffle=True, random_state=None\n",
    ")\n",
    "scores_f = cross_val_score(\n",
    "    text_clf,\n",
    "    dftest.text.values,\n",
    "    dftest.software_man_class.values,\n",
    "    cv=cv,\n",
    "    scoring=kappa_scorer,\n",
    "    n_jobs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseTransformer:\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    #    'vect__max_df': (0.7, 0.8),\n",
    "    #    'vect__min_df': (0),\n",
    "    #    'vect__stop_words': ('english', None),\n",
    "    #    'vect__analyzer': ('word', None),\n",
    "    #    'vect__strip_accents': ('unicode', None)\n",
    "    #    'vect__ngram_range': ((1,4), (1,5)),\n",
    "    #    'sel__score_func': (chi2, f_classif),\n",
    "    #    'sel__k': (150, 200, 250),\n",
    "    #    'pca__n_components': (100, 200, 500),\n",
    "    #    'pca_whiten': (True, False),\n",
    "    #    'clf__n_estimators': (2000, 5000, 10000),\n",
    "    #    'clf__criterion': ('gini', 'entropy'),\n",
    "    #    'clf__max_depth': (10, 11, 12, 15, 20, 25),\n",
    "    #    'clf__min_samples_leaf': (1, 3, 5, 7),\n",
    "    #    'clf__max_features': (2, 2.75, 0.3, 3.25, 3.5, 4),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"vect\",\n",
    "            CountVectorizer(\n",
    "                #                min_df=0\n",
    "                max_df=0.7,\n",
    "                analyzer=\"word\",\n",
    "                ngram_range=(1, 4),\n",
    "            ),\n",
    "        ),\n",
    "        #                     ('sel', SelectKBest(\n",
    "        #                score_func=chi2,\n",
    "        #                k=200,\n",
    "        #            )),\n",
    "        (\"to_dense\", DenseTransformer()),\n",
    "        (\"pca\", PCA(n_components=175)),\n",
    "        (\n",
    "            \"clf\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=1000,\n",
    "                criterion=\"gini\",\n",
    "                min_samples_leaf=5,\n",
    "                max_features=0.3,\n",
    "                max_depth=10,\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cvg = StratifiedKFold(\n",
    "    dftest.label, n_folds=10, indices=None, shuffle=True, random_state=None\n",
    ")\n",
    "gs_clf = GridSearchCV(\n",
    "    text_clf, parameters, n_jobs=3, scoring=kappa_scorer, error_score=0, cv=cvg\n",
    ")  #### !!!ATTENTION: JOBS!!!\n",
    "gs_clf = gs_clf.fit(dftest.text.values, dftest.software_man_class.values)\n",
    "\n",
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "for _param_name in sorted(parameters.keys()):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
